# ğŸš€ Scrapy Project Setup Guide (Modern Development)

This guide walks you through setting up a modern Scrapy project with best practices including virtual environments, Git, linters, and optional tooling.

---

## ğŸ“ 1. Create Project Folder

```bash
mkdir my_scrapy_project
cd my_scrapy_project
```

---

## ğŸŒ± 2. Initialize Git & `.gitignore`

```bash
git init
echo "__pycache__/
*.pyc
.env
.venv
.envrc
.idea/
*.sqlite3
*.log
output/
.scrapy/" > .gitignore
```

---

## ğŸ 3. Set Up Virtual Environment

```bash
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

---

## ğŸ•· 4. Install Scrapy

```bash
pip install scrapy
```

---

## âš™ï¸ 5. Create Scrapy Project

```bash
scrapy startproject myproject .
```

**Project structure:**

```
my_scrapy_project/
â”œâ”€â”€ myproject/
â”‚   â”œâ”€â”€ spiders/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py
â”‚   â”œâ”€â”€ middlewares.py
â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”œâ”€â”€ settings.py
â”œâ”€â”€ scrapy.cfg
â”œâ”€â”€ .venv/
â””â”€â”€ .gitignore
```

---

## ğŸ“¦ 6. Freeze Dependencies

```bash
pip freeze > requirements.txt
```

Or use `pip-tools`:

```bash
pip install pip-tools
pip-compile
```

---

## ğŸ”§ 7. Optional Tools

### ğŸ“˜ Poetry (Alternative Env Manager)

```bash
pip install poetry
poetry init
poetry add scrapy
```

### ğŸ§¹ Pre-commit Hooks

```bash
pip install pre-commit
```

`.pre-commit-config.yaml`:
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: end-of-file-fixer
      - id: trailing-whitespace
      - id: check-added-large-files
```

```bash
pre-commit install
```

### ğŸ¨ Black + Ruff (Formatting + Linting)

```bash
pip install black ruff
```

Add to `pyproject.toml`:
```toml
[tool.black]
line-length = 88

[tool.ruff]
line-length = 88
```

Then run:
```bash
black .
ruff .
```

---

## ğŸ“¥ 8. Git Commit

```bash
git add .
git commit -m "Initial Scrapy project setup"
```

---

## â˜ï¸ 9. (Optional) Push to GitHub

Using GitHub CLI:
```bash
gh repo create my_scrapy_project --public --source=. --push
```

Or manually:
```bash
git remote add origin https://github.com/yourusername/my_scrapy_project.git
git push -u origin main
```

---

## âœ… Ready to Scrape!

Want to go further?
- [ ] Add Docker support
- [ ] Set up CI/CD with GitHub Actions
- [ ] Integrate with MongoDB/PostgreSQL
- [ ] Use Scrapyd or Crawlera for deployment
- [ ] Add logs or alerts for crawl failures

---

Happy crawling! ğŸ•¸ï¸
